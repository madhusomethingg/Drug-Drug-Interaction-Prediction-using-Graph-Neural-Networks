{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drug_API.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch Geometric (PyG) API Demo: Data, Batching, GATConv, Pooling, and a Thin Wrapper**\n",
    "\n",
    "This notebook is an **API-style demonstration of PyTorch Geometric**.  \n",
    "It is intentionally **tool-focused** and avoids any domain- or project-specific content.\n",
    "\n",
    "What is covered:\n",
    "- Constructing graphs using `torch_geometric.data.Data`\n",
    "- Batching multiple graphs using `torch_geometric.loader.DataLoader`\n",
    "- Using `GATConv` for message passing\n",
    "- Using `global_mean_pool` to obtain graph-level embeddings\n",
    "- A minimal wrapper module that exposes a clean `forward()` for:\n",
    "  - graph encoding (graph → embedding)\n",
    "  - pair scoring (graph A + graph B → score)\n",
    "\n",
    "Everything uses **tiny synthetic graphs** so it runs fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core PyG objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) PyG Graph Representation with `Data`**\n",
    "\n",
    "A PyG graph is commonly represented as:\n",
    "- `x`: node feature matrix of shape `[num_nodes, num_node_features]`\n",
    "- `edge_index`: connectivity of shape `[2, num_edges]` with directed edges\n",
    "\n",
    "Optional fields that become important when batching:\n",
    "- `batch`: assigned by `DataLoader` to indicate which node belongs to which graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper: build a tiny synthetic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy_graph(num_nodes: int, num_node_features: int, edges: list[tuple[int, int]]) -> Data:\n",
    "    \"\"\"\n",
    "    Create a tiny synthetic graph for API demonstration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_nodes : int\n",
    "        Number of nodes in the graph.\n",
    "    num_node_features : int\n",
    "        Dimensionality of node features.\n",
    "    edges : list of (src, dst)\n",
    "        Directed edges. If you want an undirected graph, include both directions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Data\n",
    "        PyG graph object with fields `x` and `edge_index`.\n",
    "    \"\"\"\n",
    "    x = torch.randn(num_nodes, num_node_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a few graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3, 5], edge_index=[2, 4]),\n",
       " Data(x=[4, 5], edge_index=[2, 6]),\n",
       " Data(x=[5, 5], edge_index=[2, 6]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = 5\n",
    "\n",
    "g1 = make_toy_graph(\n",
    "    num_nodes=3,\n",
    "    num_node_features=num_node_features,\n",
    "    edges=[(0, 1), (1, 0), (1, 2), (2, 1)]\n",
    ")\n",
    "\n",
    "g2 = make_toy_graph(\n",
    "    num_nodes=4,\n",
    "    num_node_features=num_node_features,\n",
    "    edges=[(0, 1), (1, 0), (1, 2), (2, 1), (2, 3), (3, 2)]\n",
    ")\n",
    "\n",
    "g3 = make_toy_graph(\n",
    "    num_nodes=5,\n",
    "    num_node_features=num_node_features,\n",
    "    edges=[(0, 2), (2, 0), (1, 2), (2, 1), (2, 4), (4, 2)]\n",
    ")\n",
    "\n",
    "g1, g2, g3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching with DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Batching multiple graphs with `DataLoader`**\n",
    "\n",
    "PyG batches graphs by concatenating all nodes and edges into a single big graph,\n",
    "and it provides a `batch` vector that maps each node to its original graph id.\n",
    "\n",
    "This is the standard pattern for graph-level tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader batch demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch.x shape       : (12, 5)\n",
      "Batch.edge_index shape: (2, 16)\n",
      "Batch.batch shape   : (12,)\n",
      "Graphs in batch     : 3\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader([g1, g2, g3], batch_size=3, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(\"Batch.x shape       :\", tuple(batch.x.shape))\n",
    "print(\"Batch.edge_index shape:\", tuple(batch.edge_index.shape))\n",
    "print(\"Batch.batch shape   :\", tuple(batch.batch.shape))\n",
    "print(\"Graphs in batch     :\", int(batch.batch.max().item()) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native PyG: GATConv forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Native PyG layer demo: `GATConv`**\n",
    "\n",
    "`GATConv` performs attention-based message passing.\n",
    "It updates node embeddings using neighbor information with learned attention weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native GATConv on batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node embeddings shape: (12, 16)\n"
     ]
    }
   ],
   "source": [
    "in_channels = num_node_features\n",
    "out_channels = 8\n",
    "heads = 2\n",
    "\n",
    "gat = GATConv(in_channels=in_channels, out_channels=out_channels, heads=heads, concat=True)\n",
    "\n",
    "node_emb = gat(batch.x, batch.edge_index)\n",
    "print(\"Node embeddings shape:\", tuple(node_emb.shape))  # [total_nodes_in_batch, out_channels * heads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling to get graph embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Graph-level embeddings using `global_mean_pool`**\n",
    "\n",
    "Many pipelines need a single vector per graph. Pooling aggregates node embeddings:\n",
    "- `global_mean_pool` computes the mean of node embeddings for each graph in the batch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph embeddings shape: (3, 16)\n"
     ]
    }
   ],
   "source": [
    "graph_emb = global_mean_pool(node_emb, batch.batch)\n",
    "print(\"Graph embeddings shape:\", tuple(graph_emb.shape))  # [num_graphs_in_batch, hidden_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thin wrapper layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Thin wrapper layer (clean forward pass)**\n",
    "\n",
    "This wrapper is intentionally minimal:\n",
    "- `GATGraphEncoder`: graph batch → graph embeddings\n",
    "- `GraphPairScorer`: (graph A, graph B) → logit\n",
    "\n",
    "It is still PyG-driven (Data, DataLoader batching, GATConv, pooling), just packaged\n",
    "in a reusable way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper: encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATGraphEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Minimal graph encoder using PyG's GATConv + global mean pooling.\n",
    "\n",
    "    Input:  batched Data object with fields x, edge_index, batch\n",
    "    Output: graph embeddings of shape [num_graphs, emb_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, emb_dim: int, heads: int = 2):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels=in_dim, out_channels=hidden_dim, heads=heads, concat=True)\n",
    "        self.gat2 = GATConv(in_channels=hidden_dim * heads, out_channels=emb_dim, heads=1, concat=True)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        x = self.gat1(data.x, data.edge_index)\n",
    "        x = self.act(x)\n",
    "        x = self.gat2(x, data.edge_index)\n",
    "\n",
    "        # graph-level embedding\n",
    "        g = global_mean_pool(x, data.batch)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper: pair scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPairScorer(nn.Module):\n",
    "    \"\"\"\n",
    "    Scores a pair of graphs using an encoder + small MLP head.\n",
    "\n",
    "    Strategy:\n",
    "    - encode A -> ea\n",
    "    - encode B -> eb\n",
    "    - combine -> [ea, eb, |ea-eb|, ea*eb]\n",
    "    - MLP -> logit\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder: nn.Module, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch_a: Data, batch_b: Data) -> torch.Tensor:\n",
    "        ea = self.encoder(batch_a)\n",
    "        eb = self.encoder(batch_b)\n",
    "\n",
    "        combined = torch.cat([ea, eb, torch.abs(ea - eb), ea * eb], dim=1)\n",
    "        logit = self.head(combined).squeeze(-1)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Pair batching with PyG**\n",
    "\n",
    "To score many pairs efficiently, we batch all \"left\" graphs together and all \"right\"\n",
    "graphs together using two DataLoaders, then score them in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build synthetic pairs and batch them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left batch graphs : 6\n",
      "Right batch graphs: 6\n",
      "Labels shape      : (6,)\n"
     ]
    }
   ],
   "source": [
    "# Synthetic pairs: (left_graph, right_graph, label)\n",
    "pairs = [\n",
    "    (g1, g2, 1),\n",
    "    (g1, g1, 0),\n",
    "    (g2, g3, 0),\n",
    "    (g3, g1, 1),\n",
    "    (g2, g1, 1),\n",
    "    (g3, g3, 0),\n",
    "]\n",
    "\n",
    "left_graphs  = [p[0] for p in pairs]\n",
    "right_graphs = [p[1] for p in pairs]\n",
    "labels = torch.tensor([p[2] for p in pairs], dtype=torch.float)\n",
    "\n",
    "left_loader  = DataLoader(left_graphs, batch_size=len(left_graphs), shuffle=False)\n",
    "right_loader = DataLoader(right_graphs, batch_size=len(right_graphs), shuffle=False)\n",
    "\n",
    "batch_left = next(iter(left_loader))\n",
    "batch_right = next(iter(right_loader))\n",
    "\n",
    "print(\"Left batch graphs :\", int(batch_left.batch.max().item()) + 1)\n",
    "print(\"Right batch graphs:\", int(batch_right.batch.max().item()) + 1)\n",
    "print(\"Labels shape      :\", tuple(labels.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model + ROC-AUC sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: [0.1037, 0.1027, 0.0391, 0.0569, 0.0781, 0.0358]\n",
      "Probs : [0.5259, 0.5256, 0.5098, 0.5142, 0.5195, 0.5089]\n",
      "ROC-AUC (synthetic): 0.7778\n"
     ]
    }
   ],
   "source": [
    "encoder = GATGraphEncoder(in_dim=num_node_features, hidden_dim=8, emb_dim=16, heads=2)\n",
    "model = GraphPairScorer(encoder=encoder, emb_dim=16)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(batch_left, batch_right)\n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "print(\"Logits:\", [round(v, 4) for v in logits.tolist()])\n",
    "print(\"Probs :\", [round(v, 4) for v in probs.tolist()])\n",
    "print(\"ROC-AUC (synthetic):\", round(roc_auc_score(labels.numpy(), probs.numpy()), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal perturbation sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Minimal sensitivity demo (perturbation baseline)**\n",
    "\n",
    "A quick, tool-level baseline to probe sensitivity:\n",
    "- perturb one node feature column in a graph batch\n",
    "- see how pair probabilities shift\n",
    "\n",
    "This is not a full interpretability framework; it's a lightweight sanity tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturb + measure change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested feature column: 0\n",
      "Mean |prob|: 0.0016743242740631104\n",
      "Max  |prob|: 0.002989351749420166\n"
     ]
    }
   ],
   "source": [
    "def perturb_feature_column(data: Data, col_idx: int, delta: float = 0.25) -> Data:\n",
    "    out = Data(\n",
    "        x=data.x.clone(),\n",
    "        edge_index=data.edge_index.clone(),\n",
    "        batch=data.batch.clone()\n",
    "    )\n",
    "    out.x[:, col_idx] += delta\n",
    "    return out\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    base_probs = torch.sigmoid(model(batch_left, batch_right))\n",
    "\n",
    "col_to_test = 0\n",
    "with torch.no_grad():\n",
    "    pert_left = perturb_feature_column(batch_left, col_idx=col_to_test, delta=0.25)\n",
    "    pert_probs = torch.sigmoid(model(pert_left, batch_right))\n",
    "\n",
    "diff = (pert_probs - base_probs).abs()\n",
    "\n",
    "print(f\"Tested feature column: {col_to_test}\")\n",
    "print(\"Mean |prob|:\", float(diff.mean()))\n",
    "print(\"Max  |prob|:\", float(diff.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated core PyTorch Geometric APIs:\n",
    "- `Data(x, edge_index)` for graph representation\n",
    "- `DataLoader` batching with the `batch` vector\n",
    "- `GATConv` for attention-based message passing\n",
    "- `global_mean_pool` for graph-level embeddings\n",
    "\n",
    "It also included a thin wrapper that packages the same PyG operations into:\n",
    "- a reusable encoder (graph → embedding)\n",
    "- a reusable pair scorer (graph pair → logit)\n",
    "\n",
    "All data was synthetic to keep the notebook fast and independent of any project context.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "eea2fbdaf8f4a49201191cb74f1b43d0f108fb5b59f7a419e49eb8edba370613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
